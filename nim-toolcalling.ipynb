{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77d79657",
   "metadata": {},
   "source": [
    "\n",
    "# NVIDIA NIMs with Tool Calling for Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fdde48",
   "metadata": {},
   "source": [
    "This notebook will use a [NVIDIA Llama 3.1 NIM](https://developer.nvidia.com/blog/supercharging-llama-3-1-across-nvidia-platforms/) with tool-calling agent capabilities in generative AI solutions. As mentioned in this [Introductory Blog on LLM Agents](https://developer.nvidia.com/blog/introduction-to-llm-agents/), agents can be described as AI systems that use LLMs to reason through a problem, create a plan to solve the problem, execute the plan with the help of a set of tools, and use memory to store meaningful context of the system state. \n",
    "\n",
    "The notebook is designed to provide an intro to merely one of the capabilities of agent systems: **tool calling**. \n",
    "\n",
    "**Tools** are interfaces that accept input, execute an action, and then return a result of that action in a structured output according to a pre-defined schema. They often encompass external API calls that the agent can use to perform tasks that go beyond the capabilities of the LLM, but do not have to be external API calls. For example, to get the current weather in San Diego, a weather tool might be used. Or to get the current score of the 49ers game, a generic web search tool or ESPN tool might be used. \n",
    "\n",
    "## What is NVIDIA NIM and How do They Support Tool Calling for Agents?\n",
    "### What is NIM?\n",
    "NIM supports models across domains like chat, embedding, and re-ranking models \n",
    "from the community as well as NVIDIA. These models are optimized by NVIDIA to deliver the best performance on NVIDIA \n",
    "accelerated infrastructure and deployed as a NIM, an easy-to-use, prebuilt containers that deploy anywhere using a single \n",
    "command on NVIDIA accelerated infrastructure. If you're new to NIMs with LangChain, check out the [documentation](https://python.langchain.com/v0.2/docs/integrations/providers/nvidia/).\n",
    "\n",
    "Now, NIMs support tool calling, also known as \"function calling\" for models that have the aforementioned capability. \n",
    "\n",
    "This notebook will demonstrate a model that supports function calling, [Llama 3.1 8b-instruct](https://build.nvidia.com/meta/llama-3_1-8b-instruct). \n",
    "\n",
    "### What does it mean for NIM to support tool usage?\n",
    "In order to support tool usage in an agent workflow, first an LLM must be trained to detect when a function should be called and output a structured response like JSON that contains the function to be called and its arguments. \n",
    "\n",
    "Next, the model is packaged as a NIM, meaning it's optimized to deliver best performance on NVIDIA accelerated infrastructure and easy to deploy as well as use. This microservice packaging also uses OpenAI compatible APIs, so developers can build world-class generative AI agents with ease.\n",
    "\n",
    "Let's see how to use tools in a couple of examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf99be44-6252-4ebb-9e26-bd8d1668d8fd",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "- an [NVIDIA API key](https://build.nvidia.com/explore/discover#llama-3_1-8b-instruct) with access to download the Llama3.1 NIM on NGC,\n",
    "- NGC CLI, Docker and NVIDIA Container Toolkit (setup in cells below),\n",
    "- Tool-calling capable NIM hosted here **or** a NIM hosted by NVIDIA (setup in cells below)\n",
    "\n",
    "Note: NIMs hosted [from NVIDIA](https://build.nvidia.com/explore/discover) can be used for exploratory purposes. More information on integrating NIMs with LangChain is available on [LangChain's documentation](https://python.langchain.com/v0.2/docs/integrations/chat/nvidia_ai_endpoints/). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3976ee-aa09-4f38-83e4-cec5d3ac9e71",
   "metadata": {},
   "source": [
    "#### 1) Download the NIM and run it locally\n",
    "\n",
    "If you've run this in a previous notebook, no need to run it again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbde4db0-ea09-43f9-8cf4-575392de4005",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "\n",
    "export NGC_API_KEY=\n",
    "\n",
    "# Log in to NGC\n",
    "echo \"${NGC_API_KEY}\" | docker login nvcr.io -u '$oauthtoken' --password-stdin\n",
    "\n",
    "# Set path to your LoRA model store\n",
    "export LOCAL_PEFT_DIRECTORY=\"$(pwd)/loras\"\n",
    "mkdir -p $LOCAL_PEFT_DIRECTORY\n",
    "pushd $LOCAL_PEFT_DIRECTORY\n",
    "popd\n",
    "\n",
    "chmod -R 777 $LOCAL_PEFT_DIRECTORY\n",
    "\n",
    "# Set up NIM cache directory\n",
    "mkdir -p $HOME/.nim-cache\n",
    "\n",
    "export NIM_PEFT_SOURCE=/workspace/loras # Path to LoRA models internal to the container\n",
    "export CONTAINER_NAME=meta-llama3_1-8b-instruct\n",
    "export NIM_CACHE_PATH=$HOME/.nim-cache\n",
    "export NIM_PEFT_REFRESH_INTERVAL=60\n",
    "\n",
    "docker run -d --name=$CONTAINER_NAME \\\n",
    "    --network=container:verb-workspace \\\n",
    "    --runtime=nvidia \\\n",
    "    --gpus all \\\n",
    "    --shm-size=16GB \\\n",
    "    -e NGC_API_KEY \\\n",
    "    -e NIM_PEFT_SOURCE \\\n",
    "    -e NIM_PEFT_REFRESH_INTERVAL \\\n",
    "    -v $HOME/.nim-cache:/home/user/.nim-cache \\\n",
    "    -v /home/ubuntu/workspace:/workspace \\\n",
    "    -w /workspace \\\n",
    "    nvcr.io/nim/meta/llama-3.1-8b-instruct:1.1.0\n",
    "\n",
    "# Check if NIM is up\n",
    "echo \"Checking if NIM is up...\"\n",
    "while true; do\n",
    "    if curl -s http://localhost:8000 > /dev/null; then\n",
    "        echo \"NIM has been started successfully!\"\n",
    "        break\n",
    "    else\n",
    "        echo \"NIM is not up yet. Checking again in 10 seconds...\"\n",
    "        sleep 10\n",
    "    fi\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120455e4",
   "metadata": {},
   "source": [
    "##  🔨 Tool Usage -- Web Search\n",
    "\n",
    "Since a LLM does not have access to the most up-to-date information on the Internet, [Tavily Search](https://docs.tavily.com/docs/tavily-api/introduction) acts as a tool to provide a generative AI application with real-time online information.  Tavily is a search engmine that is optimized for AI developers and AI agents. A singular API call abstracts searching, scraping, filtering, and extracting relevant information from online sources. \n",
    "\n",
    "We'll enhance our NIM, [Llama 3.1-8b-instruct](https://build.nvidia.com/meta/llama-3_1-8b-instruct), with Tavily search. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8f8b6f",
   "metadata": {},
   "source": [
    "Install pre-requesites. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe4ec61f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (0.1.11)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.2.12-py3-none-any.whl (990 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.6/990.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting langgraph\n",
      "  Downloading langgraph-0.2.3-py3-none-any.whl (81 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: langchain-nvidia-ai-endpoints in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (0.1.4)\n",
      "Collecting langchain-nvidia-ai-endpoints\n",
      "  Downloading langchain_nvidia_ai_endpoints-0.2.1-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: langchain-community in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (0.0.25)\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.2.11-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting langchain-openai\n",
      "  Downloading langchain_openai-0.1.20-py3-none-any.whl (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tavily-python\n",
      "  Downloading tavily_python-0.3.6-py3-none-any.whl (13 kB)\n",
      "Collecting geocoder\n",
      "  Downloading geocoder-1.38.1-py2.py3-none-any.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pydantic<3,>=1 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from langchain) (2.0.32)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from langchain) (0.1.98)\n",
      "Collecting langchain-core<0.3.0,>=0.2.27\n",
      "  Downloading langchain_core-0.2.29-py3-none-any.whl (383 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m384.0/384.0 kB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting langchain-text-splitters<0.3.0,>=0.2.0\n",
      "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from langchain) (3.10.2)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from langchain) (8.5.0)\n",
      "Collecting langgraph-checkpoint<2.0.0,>=1.0.2\n",
      "  Downloading langgraph_checkpoint-1.0.2-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: pillow<11.0.0,>=10.0.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from langchain-nvidia-ai-endpoints) (10.4.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.32.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from langchain-openai) (1.40.2)\n",
      "Collecting tiktoken<1,>=0.7\n",
      "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: httpx in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from tavily-python) (0.27.0)\n",
      "Collecting future\n",
      "  Downloading future-1.0.0-py3-none-any.whl (491 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.3/491.3 kB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from geocoder) (8.1.7)\n",
      "Collecting ratelim\n",
      "  Downloading ratelim-0.1.6-py2.py3-none-any.whl (4.0 kB)\n",
      "Requirement already satisfied: six in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from geocoder) (1.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.3.5)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (4.12.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (0.5.0)\n",
      "Requirement already satisfied: sniffio in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (4.4.0)\n",
      "Requirement already satisfied: tqdm>4 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (4.66.5)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: certifi in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from httpx->tavily-python) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from httpx->tavily-python) (1.0.5)\n",
      "Requirement already satisfied: idna in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from httpx->tavily-python) (3.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from httpcore==1.*->httpx->tavily-python) (0.14.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Collecting regex>=2022.1.18\n",
      "  Downloading regex-2024.7.24-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (776 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.5/776.5 kB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: decorator in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from ratelim->geocoder) (5.1.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain-openai) (1.2.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.27->langchain) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Installing collected packages: regex, ratelim, future, tiktoken, geocoder, tavily-python, langchain-core, langgraph-checkpoint, langchain-text-splitters, langchain-openai, langchain-nvidia-ai-endpoints, langgraph, langchain, langchain-community\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.1.29\n",
      "    Uninstalling langchain-core-0.1.29:\n",
      "      Successfully uninstalled langchain-core-0.1.29\n",
      "  Attempting uninstall: langchain-text-splitters\n",
      "    Found existing installation: langchain-text-splitters 0.0.2\n",
      "    Uninstalling langchain-text-splitters-0.0.2:\n",
      "      Successfully uninstalled langchain-text-splitters-0.0.2\n",
      "  Attempting uninstall: langchain-nvidia-ai-endpoints\n",
      "    Found existing installation: langchain-nvidia-ai-endpoints 0.1.4\n",
      "    Uninstalling langchain-nvidia-ai-endpoints-0.1.4:\n",
      "      Successfully uninstalled langchain-nvidia-ai-endpoints-0.1.4\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.1.11\n",
      "    Uninstalling langchain-0.1.11:\n",
      "      Successfully uninstalled langchain-0.1.11\n",
      "  Attempting uninstall: langchain-community\n",
      "    Found existing installation: langchain-community 0.0.25\n",
      "    Uninstalling langchain-community-0.0.25:\n",
      "      Successfully uninstalled langchain-community-0.0.25\n",
      "Successfully installed future-1.0.0 geocoder-1.38.1 langchain-0.2.12 langchain-community-0.2.11 langchain-core-0.2.29 langchain-nvidia-ai-endpoints-0.2.1 langchain-openai-0.1.20 langchain-text-splitters-0.2.2 langgraph-0.2.3 langgraph-checkpoint-1.0.2 ratelim-0.1.6 regex-2024.7.24 tavily-python-0.3.6 tiktoken-0.7.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U langchain langgraph langchain-nvidia-ai-endpoints langchain-community langchain-openai tavily-python geocoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e190dc5e",
   "metadata": {},
   "source": [
    "Declare your model that supports tool calling. In this example, we use [Llama 3.1-8b-instruct](https://build.nvidia.com/meta/llama-3_1-8b-instruct). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "579881ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "\n",
    "llm = ChatNVIDIA(model=\"meta/llama-3_1-8b-instruct\",\n",
    "                base_url=\"http://localhost:8000/v1\")\n",
    "\n",
    "# if you do not have a downloaded NIM hosted (done in the prerequisites in this notebook)\n",
    "# you can use NVIDIA's hosted NIMs capable of tool calling. Uncomment the snippet below and\n",
    "# be sure your API key is set.\n",
    "# llm = ChatNVIDIA(model=\"meta/llama-3.1-8b-instruct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce17567",
   "metadata": {},
   "source": [
    "Initialize [Tavily Tool](https://python.langchain.com/v0.2/docs/integrations/tools/tavily_search/)\n",
    "\n",
    "Note that this requires an API key - they have a free tier, but if you don't have one or don't want to create one, you can always ignore this step or use a different tool. \n",
    "\n",
    "Once you create your API key, you will need to set it in the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8832545-d3c1-404f-afdb-6a00891f84c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your Tavily API key:  ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Enter your Tavily API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1d1511d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# Declare a single tool, Tavily search\n",
    "tools = [TavilySearchResults(max_results=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd230847",
   "metadata": {},
   "source": [
    "Create [ReAct agent](https://python.langchain.com/v0.2/docs/concepts/#react-agents), prebuilt in [LangGraph](https://langchain-ai.github.io/langgraph/#overview). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da73ae35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain.callbacks.tracers import ConsoleCallbackHandler\n",
    "\n",
    "app = create_react_agent(llm, tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be70d7ee",
   "metadata": {},
   "source": [
    "Run agent; a callback is passed to provide more verbose output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02a109cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"messages\": [\n",
      "    [\n",
      "      \"human\",\n",
      "      \"What is the weather in Paris, France right now?\"\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"messages\": [\n",
      "    [\n",
      "      \"human\",\n",
      "      \"What is the weather in Paris, France right now?\"\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"messages\": [\n",
      "    [\n",
      "      \"human\",\n",
      "      \"What is the weather in Paris, France right now?\"\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:agent] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:agent > chain:call_model] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:agent > chain:call_model > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:agent > chain:call_model > chain:RunnableSequence > chain:StateModifier] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:agent > chain:call_model > chain:RunnableSequence > chain:StateModifier] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:agent > chain:call_model > chain:RunnableSequence > llm:ChatNVIDIA] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: What is the weather in Paris, France right now?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:agent > chain:call_model > chain:RunnableSequence > llm:ChatNVIDIA] [6.37s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"I'm sorry, but I cannot access current weather data. I can provide general information about Paris and its weather patterns.\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"I'm sorry, but I cannot access current weather data. I can provide general information about Paris and its weather patterns.\",\n",
      "            \"response_metadata\": {\n",
      "              \"role\": \"assistant\",\n",
      "              \"content\": \"I'm sorry, but I cannot access current weather data. I can provide general information about Paris and its weather patterns.\",\n",
      "              \"token_usage\": {\n",
      "                \"prompt_tokens\": 259,\n",
      "                \"total_tokens\": 283,\n",
      "                \"completion_tokens\": 24\n",
      "              },\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"model_name\": \"meta/llama-3_1-8b-instruct\"\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-8f2e8d9d-bbec-4de9-8fa2-3f17cf0b81ba-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": \"I'm sorry, but I cannot access current weather data. I can provide general information about Paris and its weather patterns.\",\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 259,\n",
      "      \"total_tokens\": 283,\n",
      "      \"completion_tokens\": 24\n",
      "    },\n",
      "    \"finish_reason\": \"stop\",\n",
      "    \"model_name\": \"meta/llama-3_1-8b-instruct\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:agent > chain:call_model > chain:RunnableSequence] [6.37s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:agent > chain:call_model] [6.37s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:agent > chain:ChannelWrite<agent,messages>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:agent > chain:ChannelWrite<agent,messages>] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:agent > chain:should_continue] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:agent > chain:should_continue] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"end\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:agent] [6.38s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph] [6.39s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the weather in Paris, France right now?',\n",
       " 'output': \"I'm sorry, but I cannot access current weather data. I can provide general information about Paris and its weather patterns.\"}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is the weather in Paris, France right now?\"\n",
    "messages = app.invoke({\"messages\": [(\"human\", query)]}, config={'callbacks': [ConsoleCallbackHandler()]})\n",
    "{\n",
    "    \"input\": query,\n",
    "    \"output\": messages[\"messages\"][-1].content,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e9bbb9",
   "metadata": {},
   "source": [
    "## 🔨 Tool Usage -- Adding on a Custom Tool\n",
    "\n",
    "Let's see how to [define a custom tool](https://python.langchain.com/v0.2/docs/how_to/custom_tools/) for your NIM agent and how it handles multiple tools.  \n",
    "\n",
    "We'll enhance the NIM with Tavily search with some custom tools to determine a user's current location (based on IP address) and return a latitude and longitude. We will use these tools to have Tavily look up the weather in the user's current location."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46052285-7331-44c2-a7dc-34ebbe4d6b8c",
   "metadata": {},
   "source": [
    "First, let's create a custom tool to determine a user's location based off IP address. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9d8ed5f-b6e9-495f-85ff-e431d39475c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geocoder\n",
    "from langchain.tools import tool\n",
    "from typing import Tuple\n",
    "\n",
    "@tool\n",
    "def get_current_location() -> list:\n",
    "    \"\"\"Return the current location of the user based on IP address\"\"\"\n",
    "    loc = geocoder.ip('me')\n",
    "    return loc.latlng    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089e3223-50f3-4e8e-9043-24c792ca7daf",
   "metadata": {},
   "source": [
    "Let's update the tools to use the Tavily tool delcared earlier and also add the `get_current_location` tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b71d7d05-d3ec-4005-911c-3e44df8102b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare two tools: Tavily and custom get_current_location tool.\n",
    "tools = [TavilySearchResults(max_results=1), get_current_location]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd04f130-3f9b-4a0d-a018-d954dc41ad4b",
   "metadata": {},
   "source": [
    "We already declared our LLM, so we don't need to redeclare it. However, we do want to update the agent to have the updated tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64a0eead-ee86-4b0b-8ae3-fb194ea69186",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"messages\": [\n",
      "    [\n",
      "      \"human\",\n",
      "      \"What is the weather?\"\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"messages\": [\n",
      "    [\n",
      "      \"human\",\n",
      "      \"What is the weather?\"\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"messages\": [\n",
      "    [\n",
      "      \"human\",\n",
      "      \"What is the weather?\"\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:agent] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:agent > chain:call_model] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:agent > chain:call_model > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:agent > chain:call_model > chain:RunnableSequence > chain:StateModifier] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:agent > chain:call_model > chain:RunnableSequence > chain:StateModifier] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:agent > chain:call_model > chain:RunnableSequence > llm:ChatNVIDIA] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: What is the weather?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:agent > chain:call_model > chain:RunnableSequence > llm:ChatNVIDIA] [6.56s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"I can't provide real-time weather information. However, I can suggest some general information about weather if that helps. Can I help you with anything else?\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"I can't provide real-time weather information. However, I can suggest some general information about weather if that helps. Can I help you with anything else?\",\n",
      "            \"response_metadata\": {\n",
      "              \"role\": \"assistant\",\n",
      "              \"content\": \"I can't provide real-time weather information. However, I can suggest some general information about weather if that helps. Can I help you with anything else?\",\n",
      "              \"token_usage\": {\n",
      "                \"prompt_tokens\": 302,\n",
      "                \"total_tokens\": 333,\n",
      "                \"completion_tokens\": 31\n",
      "              },\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"model_name\": \"meta/llama-3_1-8b-instruct\"\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-424f8a19-7f27-469a-98a6-45f6990bdf2b-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": \"I can't provide real-time weather information. However, I can suggest some general information about weather if that helps. Can I help you with anything else?\",\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 302,\n",
      "      \"total_tokens\": 333,\n",
      "      \"completion_tokens\": 31\n",
      "    },\n",
      "    \"finish_reason\": \"stop\",\n",
      "    \"model_name\": \"meta/llama-3_1-8b-instruct\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:agent > chain:call_model > chain:RunnableSequence] [6.56s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:agent > chain:call_model] [6.56s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:agent > chain:ChannelWrite<agent,messages>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:agent > chain:ChannelWrite<agent,messages>] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:agent > chain:should_continue] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:agent > chain:should_continue] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"end\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:agent] [6.57s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph] [6.58s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the weather?',\n",
       " 'output': \"I can't provide real-time weather information. However, I can suggest some general information about weather if that helps. Can I help you with anything else?\"}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain.globals import set_verbose\n",
    "from langchain.callbacks.tracers import ConsoleCallbackHandler\n",
    "\n",
    "set_verbose(True) # verbose output to follow function calling\n",
    "\n",
    "query = \"What is the weather?\"\n",
    "app = create_react_agent(llm, tools)\n",
    "\n",
    "\n",
    "messages = app.invoke({\"messages\": [(\"human\", query)]}, config={'callbacks': [ConsoleCallbackHandler()]})\n",
    "{\n",
    "    \"input\": query,\n",
    "    \"output\": messages[\"messages\"][-1].content,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147c4727",
   "metadata": {},
   "source": [
    "In order to execute this query, first a tool to get the current location needs to be called. Then a tool to get the current weather at that location needs to be called. \n",
    "Finally, the result is returned to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ace95bd-f2f7-469e-9d9e-ea7b4c57e8f4",
   "metadata": {},
   "source": [
    "Below, you can see a diagram of the application's graph. The agent continues to use tools until the query is resolved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "128b55cf-5ee3-42d2-897b-173a6d696921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/4gHYSUNDX1BST0ZJTEUAAQEAAAHIAAAAAAQwAABtbnRyUkdCIFhZWiAH4AABAAEAAAAAAABhY3NwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQAA9tYAAQAAAADTLQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlkZXNjAAAA8AAAACRyWFlaAAABFAAAABRnWFlaAAABKAAAABRiWFlaAAABPAAAABR3dHB0AAABUAAAABRyVFJDAAABZAAAAChnVFJDAAABZAAAAChiVFJDAAABZAAAAChjcHJ0AAABjAAAADxtbHVjAAAAAAAAAAEAAAAMZW5VUwAAAAgAAAAcAHMAUgBHAEJYWVogAAAAAAAAb6IAADj1AAADkFhZWiAAAAAAAABimQAAt4UAABjaWFlaIAAAAAAAACSgAAAPhAAAts9YWVogAAAAAAAA9tYAAQAAAADTLXBhcmEAAAAAAAQAAAACZmYAAPKnAAANWQAAE9AAAApbAAAAAAAAAABtbHVjAAAAAAAAAAEAAAAMZW5VUwAAACAAAAAcAEcAbwBvAGcAbABlACAASQBuAGMALgAgADIAMAAxADb/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsKCwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRT/2wBDAQMEBAUEBQkFBQkUDQsNFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBT/wAARCAFCAN8DASIAAhEBAxEB/8QAHQABAAICAwEBAAAAAAAAAAAAAAYHBQgCAwQBCf/EAFkQAAEDAwICAwYODQkFCQAAAAECAwQABQYREgchCBMxFBYiQVGUFTI4VFVWYXaSlbTR0tMXIzZSU3FzdYGTobGzCRgkNDdCYtThNUNygqIlM0RXdJGjssL/xAAbAQEBAAMBAQEAAAAAAAAAAAAAAQIDBQQGB//EADMRAQABAgIHBgUEAwEAAAAAAAABAhEDUQQSEyExUpEUQWGhwdEFFSNxsTIzgfAiQuHx/9oADAMBAAIRAxEAPwD9U6UpQKUpQKUpQK4uOoZQVuLShA7VKOgFYi93iQxIattsbQ/dZCStJd16mO2ORdd056a8koGhWeQKQFrR5G8CtkhwP3dKr/L1J625AOJTry0Q3psQPFyTr5STqa3RRTEa1c2/K2zZBWUWZCiFXeACO0GSj56+d9Vk9mIHnSPnonFLIkACzwAByAEVHzV971rL7EQPNkfNWX0fHyXc+d9Vk9mIHnSPnp31WT2YgedI+evvetZfYiB5sj5qd61l9iIHmyPmp9Hx8jc+d9Vk9mIHnSPnp31WT2YgedI+evvetZfYiB5sj5qd61l9iIHmyPmp9Hx8jc+d9Vk9mIHnSPnr0RL1b569kWfGkr+9ZeSo/sNdHetZfYiB5sj5q6JmD47cG9kmw215I7N8RskfiOnI+6KfR8fJNzN0qLrtUzEkmRanJdwtyBq5aXXOtWlPjLC1eFr/AIFKKTponb45DCmsXKIzKjOB6O8kLQtPYQawrotGtTN4/vEs76UpWpClKUClKUClKUClKUClKUClKUClKUEYwXS4R7he16KeuUt0pVz5MNrU2yn8W1O7QctVq8upk9Rjh0O58ZTBVqHYEmREWCNPSOqCT+Ip2qHuKFe7Kc0x7B4LU3I77bMfhuuBluRdJjcZtayCQkKWQCrRJOnboD5K9Gkfu1R4+Xd5LPFmajfEXP7Twuwu6ZRe1PC229CVOCM31jqypaUIQhPjUpakpHYNTzIHOsH/ADheFf8A5l4f8fRfrKxeVcS8J4j4pebFjszF+J9wkRiFYvGvcVSpjW5IWNdygNEknUjTUDmO0edEc4ndIe+YzgtkvlrwTIYkyZksGzP2+7RGEPhtx1sLKB3QEErSvYhQUU7/AE2gBIl2V8aHcRtdsmP8P8znqlxVS341ugMvrgJT6ZLxD2zd/hQpZPi1qnI/CTiO9wluUVNrkNqtmV2++43i14vCJclmJGdZcVFVL3KSNykObAVqCQUgq8mV4jYXmPEXM7TfL5w1XkVjdsqorOMXC8xksWm4de5rJkJCyh0LaLWi2+sUjaoBOpoLBvfSQxu3Lwhu22685O7mcB64WZuzRkLU+22lpagrrFo2Ha8D4WgG1W4pIAOJwDjpkGWcbcrxGXhV4g2u3NQCzKW3GHcZdYccWZREhRO4pCUdWlXYd2nbUW4O8IsvxebwNN3swipxTHrtarm4JTLiWnVrjpZKdqiVJcSypQ0HIaBW08qlaLdkfDrjzmOSqsaLhh2SRLeuTehcGI6LT3Kh1Dqn0OqSpSNqgvcjXTQ60F1UqAJ6QfC1aglPErEFKJ0AF+i6n/5K5McfuGEp9tlniPiTzzighDbd9iqUpROgAAc5knxUE9qMY1pbMlyCzI0SwktXJhA18BL5cCx+tadV/wA9Seozakd15/kEtIPVx4kSBqU6DrAXXVc/H4LzVejD/RXE5esLHek1KUrzoUpSgUpSgUpSgUpSgUpSgUpSgUpSgjlxju47dn7zFYXIhyUp9EYzCFLd3JASh9tI1KiEjapIG5SUp280bV5eNJg3yG3IYcYnRVc0OIIcQT2cj+yvZWBuGE2udLcmNoft01wkrk26QuOpw6aarCCAs6ffg9g8grfFVNcRFe6Y7/7/AHwXjxZX0Mh+tGP1Y+aubUOOwvc2w22rs1SgA1He8d7xZRfkjxDuho/vb1r53kP+2m/fr2vqquzw+fylbRmlNKi3eQ/7ab9+va+qqpukhecg4U4zi8+y5PdVP3LJbfaX+6ltrHUvLKV7QEDRWg5H9lNnh8/lJaM2wVfFJC0lKgCkjQg+Oov3kP8Atpv369r6qneQ/wC2m/fr2vqqbPD5/KS0ZpB6Gwz/AOFY/Vj5qC3RAQRFZBHj6sVH+8h/20379e19VX04Il4BMq/X2U32FBnFnX8ZaCD+2mph8/lJaM3tvORpiyDbreG517WnVEQL5NA9jjpGuxHunmdNEgnlXpsFlRYrcI4cL7y3FvvvqGhddWoqWrTxczyHiAAHICuy0WSBYYxj2+K3FaJ3KCBzWr75R7VH3Tqa91Y1VxbUo4flPsUpStKFKUoFKUoFKUoFKUoFKUoFKUoFKUoFKUoFKUoFa79Nv7hsD9/Nn/iqrYitd+m39w2B+/mz/wAVVBsRSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBWu/Tb+4bA/fzZ/4qq2IrXfpt/cNgfv5s/wDFVQbEUpSgUpSgUpSgUpSgUpSgUpSgUpSgUpSgUpSgUpSgUryXW6RrLbpE6W4W40dBWtQSVHQeIAcyT2ADUkkAczUWcyLKpB6yParZFaVzS1LmLU6B/i2IKQfKAVD/ABGt+Hg14kXjh47lsmlKhHo5mHrGx+dPfV09HMw9Y2Pzp76utvZa846wWTelQj0czD1jY/Onvq6ejmYesbH5099XTstecdYLJvX4r9NPgT9gnjfdIMKMWcbu2tytJA8BLSydzQ8Q6te5IHbt2E+mr9cfRzMPWNj86e+rqoukVwEl9JK1WGHf41qhuWicJTUmNId6xTR0DzGpb5JWAnmOYKEnnpoXZa846wWRn+TX4LPcN+DEjKJ6FtXPMFtyg0rUbIjW8R+XlV1ji9R2pWjyVt1UDiXHKoERmLGtlgjxmUJbaabkOpShIGgSAG+QAAGldvo5mHrGx+dPfV07LXnHWCyb0qEejmYesbH5099XT0czD1jY/Onvq6dlrzjrBZN6VCPRzMPWNj86e+rp6OZh6xsfnT31dOy15x1gsm9Ki9nyqb6IMQL3CYhvSSUxn4jynWXVAElB3JSUK0BIHMEA89eVSivPXh1Yc2qLWKUpWtClKUClKUClKUClKUClKUEU4nnTET7s+ADr5DMZBr0EgAknQDx15uKH3JH84W/5YzWLz3GV5pg2Q4+3MXb3LrbpEFMtsaqZLrakBY7OY3a9virpYf7EfefxSvc+Y9n2MZbLlRbHkdpvUqJ/WGLfOafWzz08NKFEp5+Ws424l1tK0KC0KAUlSTqCD2EGtW2H3MYwPKOHN4xeDhGZxsQkri3uwtMuxrpEYQEuKbUpG5J1KdzbidRv3AnkRmbDc7nw+6MeFrdzq7Jud1jW1m2OMWeNLlguR0FMKMylCELOiVaLd3EAEqUQKxipGxbjiGUKW4pKEJGpUo6ACuVaYZ3mGX5zwA4i2bIrlcYV1xvJLXGMmTCiMSpLDrsRxtL7bfWNJUlTwVq2RrsRryKkmzeKObZtid/xDh7YrlfL3eJkKXcp98hQLcu4LabcQlKUNvKZjDm6ATtJAQNEkkqDWF9TbhFtjKXZklmI0t1tlK33AhJcWsIbQCf7ylKSkDtJUAOZoq4RUT24KpLKZrjSnkRi4OsU2kpClhPaUgrQCewFQ8orUTitM4n5twusuIXaNKteXXDKiLRKltR2pEuNFirmNuutsOuNoWHWkoO1WnIK0GulcbFxiey7j1jvE5hSxiTlrOMJYR45SoBubyef94KQ21p982R4qmuNxa8d1vNvsUTuq5To1uilxDXXS3ktI3rUEITuUQNVKUEgeMkAczWuWP8AEjiDb8a4acQrxkse42vMrpBiSMabgNNswmZpIZLLwHWqW2VN7t5UFDdyTyqJZvfcy4pcHYPECdkyYuOXHJrf3JizNva2NxkXVppsrfI6wu6oC1HXb2p2+MNYbctXu3SJ06E1PiuTIKUKlx0PJLkcLBKC4nXVIUASNdNQDpWNtnEDF72xGet2SWiezJlKhMORZ7TiXZCUlSmUlKjuWEgkpHMAa6VrNxcevzlk6TcHvhcaEC3xJDUhm3xG3lR3Izy1RVuJaCloCTsClErA7FAkkzK52e54Fc+BNubvSbjCeui4khp+0wUBwmHIcQ4koZBaWhKA2C1t1TrrrqausNhqVqXiHF7i/wAQYFvzTH7RfJdunTtzFm7htibWqEHy2oGQqSJQdDYUrftA3jTq9Ks3hLdsyzXPc5mXHKlpx+wZNKtcWzswWB1zSY7ZCXXdm/RKnUqTtIVqFbioEAIquLKyY6TcbI7fRdjn+hYqwKr/ACf+uY3+d2P3KqwKmk/po/n8rPApSleBClKUClKUClKUClKUClKUET4ofckfzhb/AJYzXG8W1N4tM2Ap+RFTKYWwX4jhbebCklO5CxzSoa6gjsOhrLZZZF5DYJEJpxLT5U260pY1SHG1pcRr7m5A1qB5PxRtWBWV66ZWxOx+FGKUyZUiI4uMySQkavISUaFSgkEkakgdp0rp4Ea+FFNO+YmfOI9mXGNzB4nwAsmO3Sbc7leL9mNykwF2ruvJJwkLaiLIK2kBKUJAUQNTpuOg514I3RttEbELfj3fTlDrFplMS7NLcmtKkWlTKFIbSwrqtNoQtSCHAvUHQ9leH+ebwa9vVv8A+r5qmGI8asWz62LuWMvzsgt6HSwqVbbdIkNBwAEpKkII1AUk6e6K2bCvlNWcmCY6NuNCxZlaplyvl1YyzqHLk7OmhbvXtDwZDawkFC/BbOg8AdUgJSkAg9934B2++22xpmZRkzl/sjrrkHJ0zGkXJoOABxsqDQbUhQABSpsjkKmPfnH9ir98SS/q6d+cf2Kv3xJL+rpsK+U1ZyYG1cHrfb7tilzk3q93mdjndpjP3SWl5Ty5QAcW6dgJKQCEhO1KQojTTTTzo4D4vHslqtUNEmDEtuQqyVkR1IBMlTzjikK1SQWyHVN6AA7NBry1qTd+cf2Kv3xJL+rp35x/Yq/fEkv6umwr5TVnJBce6NeN47d7PIRdL7NtFklKm2jHps0OW+3vHdtW0jYFnZvVsC1qCdeQFeGX0V8dfMiNHyHJ7fYXbm3d04/FnNiAzIS+l/VCFNlSUqcGpRu2+ESADoRZHfnH9ir98SS/q68t14kWqx22VcbjFvEGBFbU8/JkWiUhtpCRqpSlFvQADmSabCvlNWcmGyHgjYslTxBEqXcGxm0RmHcepcbHVIaaU0ks6oO07VEndu5+IdlZm/8ADu25FOxKXJflIcxmZ3bDDS0gOL6hxnRzVJ1G1xR5bTqBz05V12PihZcmtMa6Wdq6XW2yk72JkK1SXmXU66apWlBBGoPYa93fnH9ir98SS/q6bCvlk1ZyQ+wcALVimQd3WTIsltVp7uVce9uLcAm2h5St69EbN4QpRKi2FhBJPg1K8NwO34O9kTsB6S6q+XV28SRIUlQQ84htCko0SNEaNp0B1PM867e/OP7FX74kl/V0784/sVfviSX9XTYVx/rJqzk5ZP8A1zG/zux+5VWBUDhMyMtultdECXBt0CQJS3pzJZW8sJUEoQ2rwgAVBRUQByAGup2zyvNpM21aO+CSlKV4WJSlKBSlKBSlKBSlKBSsTk+V2XCrM/d7/dYdmtjA1clznktNp9zVRHM+Idpqg3+kzlfF19yBwOw1y9xNxbXmeSJXDs7XPQltJAcf08iQCPIRQbA3/IrVilpkXS9XKJabbHTuelzXkstNj3VKIArWDibxof6UGJZBgPCvCHc0tN0YcgysrvTfclmiE8g62pxJU842oBSdqdUqSlQ10qV4/wBEeLkV2j5DxgySZxTv7SusaiTh1Nohq8jUNPgnyEr1CuRKQav+JDYt8VqNFYbjRmUhDbLKAhCEjkAAOQA8goPxQwHooZlmXSBmcLHYyok21S1tXWeGl9THjoVzkJ3pSVIWkpU3qBvDiOwHUfslw84f2PhbhlrxfHIaYNotzXVMtjmpR11UtR8alElRPjJNZKFjtqtt2uV0h2yHFudz6szprEdCHpfVp2t9asDVe1Pgp3E6DkKyNApSlApSlAritCXEKQtIUhQ0KVDUEeSuVKDVvILBdOh1kkzK8WiP3Pg5cny/fscjJK3LE4o+FNipH+58a2x6UcxyA27J49kNtyyxwbxZ5rNytc1pL8aXHVuQ6gjUEGvc60h5tbbiEuNrBSpChqFA9oIrV292e6dDTIZWR49FkXTgtcXy9ebFHSVu466o+FLjJ7THJ5rbHpe0cuwNpaV4LFfbdk9mhXa0zWbjbJrSX48qOsLbdQoahSSO0V76BSlKBSlKBSlKBSlKBSlKDxXu8wscs0+7XOSiHbYEdyVJkuelaaQkqWs+4Egn9Fa8OdI3OOM61Q+CWGqftaiUHN8rQuJbUjs3MNadY/8Aj0GhHNJFWh0jvU9cUPetdPkjtOjj6nrhf71rX8kaoIFjHREtdxvLGScVb9N4r5O2d7fouAi2xT4wxDT9rA/4tQe3QGr9YYaisNsstoZZbSEIbbSEpSkcgAB2CuylApSlApSlApSlApSlApSlArg8y3JZcZebS604koW2sApUDyIIPaK50oNWLtbbl0LsgkX2yx5F04IXKQXbpaGUlx3GnlnnIjp7TGJPhIHpe0e7s9bblFvFuiz4T6JUKU0h9h9s6pcbUApKgfIQQarPpWeps4l/mCX/AAzUh4J/2NYF+YIHydugmlKUoFKUoFKUoFKUoFKUoK76R3qeuKHvWunyR2nRx9T1wv8Aeta/kjVOkd6nrih71rp8kdp0cfU9cL/eta/kjVBYlKUoFKUoFKUoFKUoFKVwcebZALi0oB7Nx0oOdK6O7Y/4dr4Yp3bH/DtfDFW05DvpXR3bH/DtfDFO7Y/4dr4Ypacho105emNMwaZm3CGTgi3GbnagzGvy7psDjb7I1dSz1J1CVlaNN/MtnmPFnehd0yLlxjulg4dw+H5hQbJZm0Tb6bv1gbQy0ltKuq6hPNa9g27+QUTz2mvR/KScFWOI/ChrMrWEPX3FtzjiGiCp6EsjrRoO3YQF8+xIc8tSH+T74KscH+CrF1uSWmcjyjZcJO8gLaY0/o7R8fJKisg8wXCD2UtOQ2mpXR3bH/DtfDFO7Y/4dr4Ypach30ro7tj/AIdr4Yp3bH/DtfDFLTkO+lcG3UPJ1QtKx2apOtc6gUpSgUpSgrvpHep64oe9a6fJHadHH1PXC/3rWv5I1TpHep64oe9a6fJHadHH1PXC/wB61r+SNUFiUpSgUpSgUpSgUpSg8N8uJtFkuE8JCzFjuP7T2Hakq0/ZUDt+H2m7QmJ13t8W8XGS2l1+XOYQ8tSiNdBuHgpGugSNAB4ql+cfcXf/AM3yP4aqxVl/2NA/9O3/APUV0tHmaMKaqZtN2XCGO7wMX9rdo8xa+jTvAxf2t2jzFr6NVZhvEniVxc1yTEIeL27BVzFsQ1XoSVzZ7DbhQuQktkJaSopVsBCidATprXa/0mbDivE3O8by+4xbTDskiE3CdaivuK6t6K26tyQpAUlCQte0LUEJ05akgmtnaMTmnql5Wd3gYv7W7R5i19GneBi/tbtHmLX0awOcccsI4cT2IeQ3owXnmEygpER99tDKiUhxbjaFJbQSlXhKIHI1hsh6QVmx3i5ZcLejS5DNytSrgm4w4UmSncXWkNJAaaUChQWpRc3bU6JCtNwq7fE556l5TfvAxf2t2jzFr6NO8DF/a3aPMWvo1BuH3HRnKuLGbYJcYyYNws0wot7wBCJzCWmluAEnm42XU7gP7q0HTtqL8HeP2RZlecAZyKFbIsDMMefnw3oLTiFCew99uZ8JxXg9SUrHj1SrmfFO0YnNPUvK4e8DF/a3aPMWvo07wMX9rdo8xa+jVPSuP+RONyrpChWw2J3P4WI29bjThW9HLyGJT5UHACetLgQQABs5hVfVcTOLF7yviF3swMUuFnxS5dxItctuS1OmgR2nlBL4cU2lR6wgat6a6a6dtO0YnNPUvK4O8DF/a3aPMWvo07wMX9rdo8xa+jVe4px27+s24fxrMyz3u5Rjkq9Fb6Fd0tONrYSG9QraNOtWFDQ80jQ+XJ2jjM3dOOd3wMRAmHFhBUe4+J6Y2G1yWAddCUNSYqtO3mvt05Xb4nNPUvKQ32w27FLLPvVlgRbTcLfHXJbdiNJZCwhJV1bm0eEhXMEEHTXUaKAIsxpwPNIcGoCgFDX3agOffcJkf5tk/wAJVTqF/U2Pyaf3Vp0mZqw6aqt83n0Wd8O+lKVzmJSlKCu+kd6nrih71rp8kdp0cfU9cL/eta/kjVOkd6nrih71rp8kdp0cfU9cL/eta/kjVBYlKUoFKUoFKUoFKUoMJnH3F3/83yP4aqxNnSF2SCk9hjoB+CKzWYMLk4le2WxuccgvoSB4yW1AVhbCtLtjty0HchUZsg+UbRXRwf2f59F7mvPCLLsh4F4XF4cXbh9lV8uVlddiW64WWAHoVwjlxSmXC+VBDJ2qAUHCNNNfHoMnc8Vusid0lSbPMWi8QWW4GsZRE0i0JbKWuX2zReqdE6+Fy7a2BpU1e5GouT2vMLnZWcdvVtzZ22rwuDFslux1DrLD05UdSJCZ7qSnYUq6sbHlJRt3agnWs5jK7xgt24O5RPxbIpkJnB1Y/OZg2x16VCl6xVaPMgb0pJZcG7TTUDnoQa2epU1Rrvb+FF1ya4cU5DLb9hyGPlwu+N3aSwpKQ6mDGQFAkfbGV6ONLA1BSVjtHKMSeG+ZWPolYLJtNpfb4jYQ6i4RLeGip1biXHG3mQBzUlbTi+Q9NonTxGtr6VdWBrzlnCudh/BzhHi1thSbnIs2T2N+cuK0p06pkpckyF6A6J3la1KPIa6k1ibZmeScOs04wwrbgOUXq9Xm9d1WZ5i2LTAdJhsNpUuUva2lAWg7jr2A+OtnKU1chrBiPDq7cFch4Ztqtc+9R8Ywa6NzHrbFceQuUXI7pZQUpOq1qCwhPplachUfh8PeKWI4VhuczBBuVxt16GSz7LbbNJN3X3cspmMFXXKCyhqQobQ0P+4R97z2/pU1IGBz77hMj/Nsn+Eqp1C/qbH5NP7qgufad42RAnTdbpCRyJ5ltQHIcz+ip5FQW4zKFDRSUAEe7pVx/wBqn7z+IZdztpSlc9iUpSgrvpHep64oe9a6fJHadHH1PXC/3rWv5I1TpHep64oe9a6fJHadHH1PXC/3rWv5I1QWJSlKBSlKBSlKBSlKBUTkcPkJdWbZe7lZGFq3dywgwppJPM7UutL2gk66Age5UspW2jEqw/0ysTZDu8Cf7c75+pg/5ao5xAdtXCzGJGQ5VxJutmtDBCVyH2oR1UexKUiKVKUfIkE8j5Kl2a8SsY4dG0JyO8xrUu7zW7fBbeJK5D61BKUpSATpqRqrsTrzIrCYtiGT3Kbk54hy7JkNrfuqZNjtrEAbILDRBaUtS9Sp0lKV+PaoEpVoQE7e04nh0j2W8sLYMCzyTl14k3DPusw5bbRs7cKFG7tWSlJWt5xTOzTXcEhKeYIJI00Mq7wJ/tzvn6mD/lqmNKdpxPDpHsXlDu8Cf7c75+pg/wCWp3gT/bnfP1MH/LVMaU7TieHSPYvKoMpw3O7ZlVjlQM4SjCm231X5dybitSmEpQS24y4GNmmvpgtI0A13c+Umt+IO3aBGnQc8u8yFJbS8xIYRAW262oapUlQjaEEEEEdutS662qHfbXMttwjNTIExlceRGeTuQ62oFKkqB7QQSCKrvAFN8N8phcLLNhtzt+IW2zJk26/F1UiMpXWELjrUrUpWNwUNyuY3aAADV2nE8OkexeWe7wJ/tzvn6mD/AJaneBP9ud8/Uwf8tUxpTtOJ4dI9i8ovBwNtuSw9cbvcb2GFhxtmb1KWgtJ1SspabQFEHQjdqAQkgbgCJRSlaa8SrEm9UpM3KUpWtClKUFd9I71PXFD3rXT5I7To4+p64X+9a1/JGqdI71PXFD3rXT5I7To4+p64X+9a1/JGqCxKUpQKUrCzcgVElOMhgK2HTXdpr+ygzVKj3fSr1uPh/wClO+lXrcfD/wBKCQ0qPd9KvW4+H/pXU5mbbTTzq0NIbZBLi1OgBGg1O4+LQc+dBJqi+QcSsaxvK7Hi0+9RYmR33rBbYC9VOPbEKUVaDsTok8yQCRoDrXmOaqvli7qskiGsSmOshz0nulg7k6ocASob08weShqPHWKxZl+2wrRIyBUXJcpgR3IxyBcNuO+tC1AqACQdgO1GoSdCUg0Hdw3xDJe9+G9xMl2XJspjT350WTBgBDVvC9UobZKhu1ShSk7+StFaEnTcbAqPd9KvW4+H/pTvpV63Hw/9KCQ0rqivd0RmndNu9IVp5K7aBSlKBUU4p4TJ4i8P71jsK/TsZmTmNjF2trhQ9GWCFJUNCCU6jRSdRqkkajXWpXWKul6NukJaDQc1SFalWnjPzUGCwTiBZb/c7xice9qu2SYuGIt3D8csOqcU0lQe2EAFK+Z1T4OuunLSplUBu8mW5Mbm2RNvtFwdkMqny3IQfclx29ftJUFIIOh0Cju2gnQc6zvfSr1uPh/6UEhpUZlZm3BivSZKGo8dlBcdeddCUISBqVKJ5AADUk122bL2L4iG9ELMiJLSlxmSw6FocQoapUlQ5KBBBBHI60EhpSlApSlBCuNtim5TwYz6zWxgyblccfnw4rKe1x1yM4hCf0qIFRnom5Tbss6OHDx+3PdamFZotskIUNFNSI7SWXUKHaCFIPb2gg+OrbrWS0H+bj0oZNoV9owLii6qZC8TcK+JA61vyAPp0I8qtoA0SaDZulKUCqs4w5cMAxLK8lLHdXoTAfmhjXTrC22VBOvi1IA1q06h+T4x3wouMKXCTMt81pTDzLmhS62pO1SSPIQSKCho10znBOG104hZHlycjEewvXRdgYtrLEZt4NdYlLTqR1mxPNJKyokc+XZWKiZZnmDXXAn8gyprI4uXNvMvxE29lhNvkdyrkNqjqQNymxsKCHCo6EHXxVYmK9G9rFmVwVXvJbzYO43Le3YrtcEvQmo607S2EhIUoBPgjepRA5CujF+jFBxq62+c7csgvvoVGdiWmPd5yHmra24jYrqQEpJOzwNyyshPLWgq7h/xBztmx8HMnveUi9xcyfat862G3MMNtKciuuodbUhIWFhTPhakpO47UoGgHn4S47kMPBuL0pvNbipTd8vbSG3YMJaA8h7cqQQWealhJSUHVGijokctLlhcBrVbrHgeNtyZykYa81Pt6FPtF93q2nGUl0BPhJ0dVrtCeYHPxHst/R9ZtN7ySbCuN7jQsgU+7Ms6ZLZhh55IS48hJQVJWdNfTbdSeVBUOEZLl2Uu8KsctmSJxqHcsBbvMxyDbIpV1ye5kjqkKR1bY+2nwQkpA1ASDoR7eHvFvKcgvHC2FcZ7a1z5d/t93LMdCEzFwlKbac00JRrt3EJIGpI7NBVs4twGh4jdMZnw1XBx7H8fGNxUvutlK4wLJ3r0SNXPtCOY0HM+D2aYk9GSA1abXFhTr3bJtrucy6wrrEkMiUw5KW4p5A3NlBQesUnapB5Ac9RrQVLknG/MYc6/2G2rkTbpMzh6xW5yJFjreiRG4DMhQbQ4pttbmpVoXVf3j6baEmyOCt1z6VNv0PMYNyFuY6hdsuV4YhsS3twUHW3ERXVt+CUoIUAnXeQRy1r0NdFCyox252tcm+vvzb13wouzk4d3RZ3Vob61l0JGh0R2EKHhKHZoBNsJ4Zz8MgSY7l3veRPSHuuXLvcpDzgO0J2pCUpShOiRySkDUk9pNBZVt/2fG/Jp/dXprogtqahMIWNFJQAR5DpXfQKUpQKjGTf19H5MfvNSesBfrfIlzELaaK0hAGoI7dTQabYnxZ4tZ9AgZjYbVepdvmzdzFn7itqbYqGHyhQL6pAkhwIBO7bpvGmzSvdkXEbPoGLcSszYyoIiYhkb8OPZfQ5gtSYzbjRUh1wp367XCElBSRpqd2tW9Yejaxi1/wC7bNecltdq7tVcO92LcEptweUrerRG3eEKUSothYQST4Nei49HS33PDczxp1y5Jg5XPeuM1xDrQdbcd2bg0dmgT9rToFBR5nmaCreIF7y/iOvixHtOSJxnHsViu28xG4DUhy4vGIHnS6pwaob0cShIRoTzOviq4Oj/AP2W8O/zHb/k6Kw2XdGaJlWQXm7M3XIcedvcYRrtHs01tpmeAgtpU4lSFaLCDt3JKToNDrViYNhSsMs9is0dDy4VqjMw2nH1JKyhtAQkqIABOiRroBz8VBO6UpQKUpQKrXpD8Im+NfCy6Y+273JeGymdaJwO1USc14TLgUOaeeqSRz2qVpVlUoKs6NvF1zjHwvh3K4tdx5Pb3V2q/QVDaqNPZO11JT/d3clgeIKA7QatOtYs0P8ANx6TFtzFH9HwTiO43aL2OxuHdUg9zST4khwapUez06ieytnaBSlKBWGzLJBh+KXe+GBMuot8VyT3FbmS7If2pJ2NoHao6aCtYumZ00Lx0ac5w+y2S0Wy8ImMKn3Rid1gdMfrQhCWVpUA2o7HhuUlY12nbyINj8Js5svSCy21cRsT4hSn7DEtJjP4UkttriyHXD9smICioK0bUlII08AqQopUdwSjAsJtN9yGLxWn45MseaXeysQ34lxkl1cFr05ZSnUpQSSN2gGu0agEq1selKBSlKBSlKBSlKBSlKBSlKBVZZfarJJ468P50vK3rde40S4JhY+hRDdySptIcWoePqxoR+OprmUm8QsQvkjHY7EvIGoL7lujytepdkhtRaSvQg7SvaDoQdCeYr8rLr/KPcQZuWW2/T8Jwdd/s6XmIkt2BMDsYODa6kf0rlqBodRQfrXSqj6LPEPNuK/B+25bnNutlrn3Vxb8KPa2XWkdx6ANrUHHFncohagQdClSOXbVuUClKUClKUCvPPuMW1RFypslmHGb5rekOBCE/jUeQr0VBZ4ReM7ntSkJfatkeOYzSxqltbnWFbgHZuICU66agAgHwjrvwcOMSZvwjesMDxgXw54w8OL9h93yyxJjXKOWku+iLJUw6PCbdSN3ahYSr9GnjqL9GbjuzfOGTFtzq8QbZllgfXaJz0yWhCJ5a8FEplaiA6hxOh3p5FW7xaVbm0eQU2jyCvVssHKesexucPso4Z7brF8ZM/Sp9lHDPbdYvjJn6Vc9o8gptHkFNlg5T1j2Xc/MnpZYjkXSR6Vt7bx5cAWWCxFgRrxcprcWH1YbClqS6s6OAOrc5N7j49K2k6HfQktXAq5t5rIy9zJb+/FXGT6EvKatyEL03g7VayNCnlv0SDodm5KVJ2S2jyCsTA2WfO4DUVCWGrnHkGS0gaJccb6socI7NwBUnXTUggE+CNJVgYdUTqXiY379/D+IN08E6pSlc9iUpSgUpSgUpSgVxWtLaFKUoJSkalROgArEZZlMPD7M5cJm5YCg20y36d5w+lQn3e0+QAEnkDWvuSXm4ZnIL17e7ob11RAST3M1z1GiOxRH36tT5NByHW0H4diaZ/le1Md/sv3Xw/xJxGK4pD2U2VlaToUuXBlJB/EVV1fZSwz23WH4zZ+lWv6GW2k7UIShPkSNBX3aPIK73yPB558kvC//ALKWGe26w/GbP0q/OTj90acfyvpe2p2zX21DCMqkeiV0nMTWuqgKSd0pClhWiFOabka9qnNBySa2c2jyCm0eQU+R4PPPkXhe9u4hYHabfGgwsnx6NDjNJZZYauLAS2hIASkDdyAAAr0fZSwz23WH4zZ+lVAbR5BTaPIKfI8HnnyLw2Bb4m4c6dEZZY1nyJuTJ/8A1UgiTI9wjofivtyWF+ldZWFpP4iOVavFCVAgpBB8RFLaXrFMMy0SF2qYTqXYvghz3Fo9Kse4oH9Fa8T4FRb6de/x/vuXhtPSohw8z1vM4LjT7aY13ihIksp9IoHscb157ToeR5pIIOvImX18pi4VeBXOHiRaYCoI1/aDkn5CH+5yp3UEa/tByT8hD/c5Xo0b/f7esMo4Srvi3xhvfD7iRgdhtuMXC/w70ZipKYCGVPOdUyVJQ0XHmwFA6KVu5bRyOvKvTl/SHseI3m8W/wBBcgvSLG0h69TbRCS8xa0qRvHXErBJCPDKWwshPMiuHGTHckXmPD7LscsvfG5jsuX3Va25Tcd1xqRGU1vQt0hGqToSCRqOyoVc8X4iYw9xIhWHDWrzGzpXdzEt25sNJtcl2Ihh5uSFHctCCgKBaCtQSOXbWUzMMU6ybpC2Gx3JcK2Wq+Ze5HgNXSY5jsRMhuHGcBU044pS0+nSlSkoRuUQNdumleO38VzeuMloat93Q/hM7CncgRtaTtWoSWUpe3bd40bWobddOfMaioZjHDvOuAk+6tYvjaM6i3ayWuEiT3ezFMWXDiCLq6l0gqaWlCF6o1UDuG3mDXp4e8Gsm4SZLw4XGhM5HAt+JPY5c3m5SWjHeLrb4dCV6FbZUhSABzGoJGlS8iy+F3F2JxXimbbsfv1stjjCJMS4XWIhpia0onatopWo89NdFBJ0IOnOpI7/AGg43+QmfubqnuBGE5VjOeXaUcWewDCn7eB3tuXZucx6IF3cp6KlBIZa2bgU+BuJB2DSrhd/tBxv8hM/c3W/DvMTfKr8SsJ3SlK5SFKUoFKUoFKUoKN4zXNc/N40Aq/o9uhpdCNf966pQJI9xKEgH/Ery84XUt4vwXIXEIvqSepnQG1tq8RW2pSVj9AW0f8AmqGTJse3RHpUt9qLFYQXHX3lhCG0AalSlHkABzJNfpGgasaJh6vC3/vmlXF3UqKJ4t4MpQSnNMeJJ0AF1Y5/9dfW+LODuuJQjMsfWtRCUpTdGCST2ADfXr2uHzR1YsQvjZZkSt5t13Nk7qEPvgEUdwdbv6v0+7dt3+Dv27dfH466pvHOzwX7mXLVeTb7XcDbp9zTGR3NGcCwnVR37inwknVKVaAjUCoLgXB0YouHYbpwys98TGlKAyhbkf7YwXCpLi0KBc61KSBppoSPTVlr3w7yGXwx4o2lq377herxKlQGeubHXNrLW1WpVonXarkog8q58YukzTe2/f3Txtw4e/3VI+IfF1jHU3612uBdbrdrfAU/IftsVLzUBSmypsulRA15btoCjpz00qU4Dc5N7wTHLjNd66ZLtsaQ+5tCd61tJUo6AADUk8gNKri945luPXXiBGtOOjILdlKS+xLbnNMKjOqjhlSHA4QSnVIIKde3SpLiuZ45g+J2GwX/ACOzWi8262xY8uFKuTCHGXEso1BBX+3sI0I5VuoxKtpM4k2jf4Rx3ffcLApUTPFzBRprmmPc+z/tVj6dZ6zX225HCEy03GJdIhUUiRDfS82SO0bkkjUV7KcSiqbUzEokWH3RViziwzEK2pdkCC6B/fbe8AJ/WdWr/lrZKtZschOXTMcdhta7lT2n1EeJDJ61RPueAB+NQHjrZmvj/jsU7aiY429d3q2d0FQZSO5+IV7Dh2qkRIrrQP8AfSkuJVp5dDpr5NyfLU5rG3vHoOQsttzWlqLZKm3WXVsutkjQlK0EKTqOXI864WDiRhzOtwmLevoQx1K8p4Z20nX0QvfxvI+nXz7Gdt9kL58byPp169pgc09P+rueuleT7Gdt9kL58byPp0+xnbfZC+fG8j6dNpgc09P+m566xKUd0cQrIGzuVHhynXQD6RKi2lOvk1Ounl2q8lewcM7aDr6IXv43kfTrN2THoOPMONwmlpLhCnHXnVvOuEDQFS1kqVoOXM8qxnGwqYnUmZm0xwz3Zm6GSpSlc5iUpSgUpSgUpSgjGf4U1mtnQyFpYnxl9dEkKGoSvQghWnalQJBH4j2gVQExh6BOct1xjmHPQnVyK7oTp2bh4lJPiUOVbTVjb5jlryaKI11gR57IOqUvthW0+VJ7Un3Rzrt6B8Tq0SNnXF6fOPt7HHi1l7ij/gGvgCghRwdQw1r/AMAq7nOB2JqUSiPPZB57UXKQR+1Z0/RXD7BmLfe3H4yf+lXf+daJlV0j3LRmpqlXL9gzFvvbj8ZP/Sp9gzFvvbj8ZP8A0qvzrRMquke5aM1NV1risuKKlstqUe0lIJq6fsGYt97cfjJ/6VPsGYt97cfjJ/6VT51omVXSPctGalO4Y3rdr4AoVtRlNMoRq66ra0wygqW6r71CBzUfcAq7U8DcVB8Jq4LSe0G5SB+0LB/9qkWO4PYcUUtdqtjEV9Y2rkaFbyx26FxRKiPcJrXX8b0emPp0zM/xHrJaEb4W8PXcbDt3uiAm7yW+qSyCFdyskglvUEgqKgCog6eCkDXbuVYNKV8jj49ek4k4mJO+QpSlecKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQf/2Q==",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(app.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ce0ec8-d5bb-4ba8-b2d6-6fe3a0c0aeec",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "You've now seen how to use NIMs to do tool calling, an important capability of agents. As mentioned earlier, tools are just one part of agent capabilities, so check out other notebook so see how tools can be used with othe techniques to create agent workflows.\n",
    "\n",
    "If you're ready to explore more complicated agent workflows, check out [this blog](https://developer.nvidia.com/blog/build-an-agentic-rag-pipeline-with-llama-3-1-and-nvidia-nemo-retriever-nims/) on how to improve your RAG pipeline with agents with Llama 3.1 and NVIDIA NemMo Retriever NIMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b32577c-0d1e-43ad-8f78-5b1b916f63bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
